{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS503_Assignment2_Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9IMNPHuzEYn",
        "outputId": "1b0fc26b-ae97-4ae5-ff26-f6080180666e"
      },
      "source": [
        "!pip install git+https://github.com/gbolmier/funk-svd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/gbolmier/funk-svd\n",
            "  Cloning https://github.com/gbolmier/funk-svd to /tmp/pip-req-build-ifpoc7td\n",
            "  Running command git clone -q https://github.com/gbolmier/funk-svd /tmp/pip-req-build-ifpoc7td\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.7/dist-packages (from funk-svd==0.0.1.dev1) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.7/dist-packages (from funk-svd==0.0.1.dev1) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from funk-svd==0.0.1.dev1) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.38.0->funk-svd==0.0.1.dev1) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.38.0->funk-svd==0.0.1.dev1) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->funk-svd==0.0.1.dev1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->funk-svd==0.0.1.dev1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->funk-svd==0.0.1.dev1) (1.15.0)\n",
            "Building wheels for collected packages: funk-svd\n",
            "  Building wheel for funk-svd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for funk-svd: filename=funk_svd-0.0.1.dev1-py3-none-any.whl size=9058 sha256=39275a8d6fd7e2fe664e6c6ed55231699e359e574816ee6596251fd21344b1e5\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-lg9edjyl/wheels/99/98/69/793c84ef2626b03661e3cddf49d8818cddbb694b0428adaeb4\n",
            "Successfully built funk-svd\n",
            "Installing collected packages: funk-svd\n",
            "Successfully installed funk-svd-0.0.1.dev1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBBwD7pjLn7M"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "from funk_svd.dataset import fetch_ml_ratings\n",
        "from funk_svd import SVD\n",
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7rN9BNfqMtT"
      },
      "source": [
        "Cloning into dataset repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3hlcLANKwys",
        "outputId": "744a11ab-ac8f-4ee3-f33a-3ac686e28764"
      },
      "source": [
        "!git clone https://github.com/gagan-iitb/DS-503"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS-503'...\n",
            "remote: Enumerating objects: 609, done.\u001b[K\n",
            "remote: Counting objects: 100% (609/609), done.\u001b[K\n",
            "remote: Compressing objects: 100% (558/558), done.\u001b[K\n",
            "remote: Total 609 (delta 337), reused 66 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (609/609), 84.67 MiB | 24.94 MiB/s, done.\n",
            "Resolving deltas: 100% (337/337), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW3yla48qPbI"
      },
      "source": [
        "Loading data into dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oj0SbD7XMCWH"
      },
      "source": [
        "train_set = pd.read_csv('/content/DS-503/Assignments/Assignment2-CollabFiltering/Training_set.csv') # train set\n",
        "val_set = pd.read_csv('/content/DS-503/Assignments/Assignment2-CollabFiltering/Validation_set.csv') # validation set\n",
        "test_set = pd.read_csv('/content/DS-503/Assignments/Assignment2-CollabFiltering/Test_set.csv')  # test set\n",
        "val_gt = pd.read_csv('/content/DS-503/Assignments/Assignment2-CollabFiltering/Validation_set_with_groundtruth.csv') # ground truth"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1l5WXhMa9AWr"
      },
      "source": [
        "Pseudo-Inverse Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkSsrRL79DBb"
      },
      "source": [
        "Assume that we have to guess the rating of an item for a given user X. We know the rating of 30 items for this user (in our validation or test set). Now, we take all the users Y, who have rated all 100 items. We  estimate that the ratings of user X are a linear weighted combination of the ratings of these users Y. So, we have an under-determined system with 30 equations and Y variables. Using the pseudo-inverse approach, we can compute the least-square estimate of the weights. Using these weights, we can estimate the ratings of all the 70 items for user X as weighted combinations of the ratings of users Y.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTdYOh1x9USQ"
      },
      "source": [
        "Finding Y from training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nps6IyepN-rV"
      },
      "source": [
        "Y = []\n",
        "\n",
        "for j in range(len(val_set)):\n",
        "  l = train_set.loc[j, :].values.tolist()[1:]\n",
        "  flag = False\n",
        "  for i in range(len(l)):\n",
        "    if l[i] == 99.0:\n",
        "      flag = True\n",
        "      break\n",
        "  if not flag: Y.append(l)\n",
        "\n",
        "# Y to matrix\n",
        "Y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6sMxHA8_xDj"
      },
      "source": [
        "Input user ID and find 30 ratings for this user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1VyrBYX-EQK",
        "outputId": "66fb546d-4abe-4420-ffef-808e1c5cbbcd"
      },
      "source": [
        "x = int(input('Enter user id :'))\n",
        "val_l = val_set.loc[x, :].values.tolist()[1:] # ratings of user x from val set\n",
        "\n",
        "ratings = []  # to store ratings\n",
        "r_indices = []  # to store indices of rated items\n",
        "missing = []\n",
        "\n",
        "# finding rated items\n",
        "\n",
        "for i in range(len(val_l)):\n",
        "\n",
        "  if val_l[i] != 99.0:\n",
        "    ratings.append(val_l[i])\n",
        "    r_indices.append(i)\n",
        "\n",
        "  else:\n",
        "    missing.append(i)\n",
        "\n",
        "# if we find 30 ratings from val set we are done. Else get ground truth ratings\n",
        "\n",
        "if len(ratings) < 30:\n",
        "  gt_l = val_gt.loc[x, :].values.tolist()[1:] # ratings of user x from gt\n",
        "  i = 0\n",
        "  while len(ratings) < 30:\n",
        "\n",
        "    if gt_l[i] != 99.0 and i in missing:\n",
        "      ratings.append(gt_l[i])\n",
        "      r_indices.append(i)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "# converting ratings to numpy array\n",
        "\n",
        "ratings = np.array(ratings)\n",
        "print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter user id56\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh78nmwZLqL-"
      },
      "source": [
        "Using pseudo inverse to estimate all ratings of user x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ADatjaA6hZk",
        "outputId": "45698550-5169-402b-a8a3-f39df105c0e7"
      },
      "source": [
        "Y_30 = Y[:, r_indices].T\n",
        "U, Sigma, VT = randomized_svd(Y_30, \n",
        "                              n_components=30,\n",
        "                              random_state=None)\n",
        "\n",
        "V = VT.T\n",
        "theta = V@np.linalg.pinv(np.diag(Sigma))@U.T@ratings\n",
        "\n",
        "print('Ratings of user {} : {}'.format(x, theta@Y.tolist()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratings of user 56 : [-1.99191821 -6.12        1.10622163 -2.51515659 -1.12573241 -0.15768791\n",
            " -2.90945783 -0.04181989 -0.33413767 -0.44        1.37183564  3.35\n",
            " -2.39318002  2.23056744 -1.90577338 -4.60800139  0.68883863 -2.33199036\n",
            "  0.03918475  0.52430498 -0.05        5.44       -0.52997374 -6.21\n",
            "  0.64002495  0.63        0.64723401  5.15        1.15088     0.60804341\n",
            " -2.55207694  1.13222328 -2.52        3.25        1.65637952  1.48683704\n",
            " -0.55866246 -2.23054358  2.2593437   1.70812809  0.73116081  3.81746562\n",
            "  1.94       -4.01180069 -0.35970364  2.41915953  1.36        0.1939729\n",
            "  0.43231819  0.66555626 -0.34        1.1547122   0.83562293  9.37\n",
            "  1.8        -0.59342912 -2.32869825 -6.89        3.35       -1.14398884\n",
            " -5.15        0.68674253  4.17        0.54831371  9.27       -2.14\n",
            "  0.27101681 -4.03        0.30140594  0.77110129  3.23559727  2.19117805\n",
            "  3.07049467  1.17076657  2.68154098  2.9650118   1.4839693   4.9\n",
            "  3.25        2.67        1.12340314  3.95516825  4.42038184  0.86136884\n",
            "  3.75524155  3.93        2.11820934  6.26        4.77107714  0.43199704\n",
            "  3.61269995  3.27617704  3.472315    2.60942388  2.90002119  1.51505273\n",
            "  1.7         1.3212324   1.89        0.92      ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lr88UKyWUfg"
      },
      "source": [
        "From this we can ibtain the remaining 70 missing ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL1kVPikVPfY"
      },
      "source": [
        "Nearest Neighbor approach: Item-Item Collaborative Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJWjJEGXVbJ6"
      },
      "source": [
        "In this approach, the rating of an item is estimated using the ratings of similar items. Assume that we have to guess the rating of an item “i” for a given user X. We first find K (e.g K=3) other items that have been rated  by  X  and  are  most  similar  to  item  “i”. Similarity can be computed using the Pearson Correlation Coefficient (take dot product after subtracting the mean). Using the correlation coefficients as weights, we can estimate the rating as the weighted average of the known ratings of items by that user. We also \n",
        "adjust for the deviation of the average ratings of the item “i” and user “X” from the overall average rating of all the items in the dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jAa2yu9W_ZR"
      },
      "source": [
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lugbgBEJJovl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdfdc67-1da0-4bcb-aa05-265d4348f7f0"
      },
      "source": [
        "user_id = int(input('Enter user id :')) # user id\n",
        "item_id = int(input('Enter item :'))  # item rating to be guessed  example 1, 1\n",
        "\n",
        "l = train_set.loc[user_id, :].values.tolist()[1:]\n",
        "\n",
        "if l[item_id] != 99.0: # if rating exists\n",
        "  print('Rating exists : {}'.format(l[item_id]))\n",
        "  raise StopExecution # this is to break cell execution\n",
        "\n",
        "# finding items most similar to the concerned item\n",
        "\n",
        "item_ratings = []\n",
        "df = train_set.drop(train_set.columns[0], axis=1)  # drop the id columns\n",
        "\n",
        "for item in df.iloc[:, item_id]:\n",
        "  if item == 99.0: item_ratings.append(0)  # treating unrated items as 0 ratings (neutral)\n",
        "  else: item_ratings.append(item)\n",
        "\n",
        "df = df.replace(99.0, 0) # replacing non ratings with 0 for computing similarity\n",
        "pearson = []  # for storing pearson correlation coefficients\n",
        "\n",
        "for column in df:\n",
        "  ratings = np.array(df[column].tolist())\n",
        "  i_rat = np.array(item_ratings)\n",
        "  ratings_m = ratings-np.mean(ratings)\n",
        "  i_rat_m = i_rat-np.mean(i_rat)\n",
        "  pearson.append(np.dot(ratings_m, i_rat_m)/(norm(ratings_m)*norm(i_rat_m)))\n",
        "\n",
        "k = 3\n",
        "\n",
        "# getting the indices of the k most similar items that have been rated by the user\n",
        "# excluding the item itself\n",
        "sim_indices = np.flip(np.argsort(pearson))\n",
        "\n",
        "w_add = 0\n",
        "w = 0\n",
        "count = 0\n",
        "for i in range(1, len(sim_indices)):  #excluding the item itself (highest similarity)\n",
        "  if l[i] != 99.0:\n",
        "    count += 1\n",
        "    w_add += pearson[i]*l[i]\n",
        "    w += pearson[i]\n",
        "  if count == k: break\n",
        "\n",
        "w_avg = w_add/w\n",
        "print('Guessed rating : {}'.format(w_avg))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter user id :1\n",
            "Enter item :1\n",
            "Guessed rating : 9.119629608248152\n"
          ]
        }
      ]
    }
  ]
}